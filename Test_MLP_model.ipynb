{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 users data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utilize.data import *\n",
    "from utilize.transform import *\n",
    "from utilize.feature_selection import *\n",
    "from utilize.test import *\n",
    "from utilize.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utilize.model' from 'C:\\\\Users\\\\zifan\\\\OneDrive\\\\Desktop\\\\Zifan Xu\\\\Datamining\\\\Projects\\\\extrasensory_Xu\\\\utilize\\\\model.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utilize.transform as transform\n",
    "import utilize.test as test\n",
    "import utilize.model as model\n",
    "importlib.reload(transform)\n",
    "importlib.reload(test)\n",
    "importlib.reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " X, y, M, user_index, feature_names, label_names = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only select body state label\n",
    "target_label = ['LYING_DOWN', 'SITTING', 'FIX_walking', 'FIX_running', 'BICYCLING', 'OR_standing']\n",
    "\n",
    "# Use the last 5 user's data as test set\n",
    "test_uuid = list(range(56, 61))\n",
    "\n",
    "# Fill the Nan with mean value and normalize all the data \n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform \n",
    "# 1. select target labels \n",
    "# 2. tansform feature matrix fill None with mean and do the normalization\n",
    "# 3. Split train, validation and test set by ratio of 6:2:2\n",
    "X_new, y_new, M_new = select_target_labels(X, y, M, target_label, label_names, drop_all_zero = False)\n",
    "X_new = pipeline.fit_transform(X_new, y_new)\n",
    "X_train, y_train, M_train, X_val, y_val, M_val, X_test, y_test, M_test = random_split(X_new, y_new, M_new, test_size = 0.2, val_size = 0.2, random_seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [29700/226408 (13%)]\tLoss: 0.655576\n",
      "Train Epoch: 0 [59700/226408 (26%)]\tLoss: 0.661621\n",
      "Train Epoch: 0 [89700/226408 (39%)]\tLoss: 0.711075\n",
      "Train Epoch: 0 [119700/226408 (52%)]\tLoss: 0.609860\n",
      "Train Epoch: 0 [149700/226408 (66%)]\tLoss: 0.630203\n",
      "Train Epoch: 0 [179700/226408 (79%)]\tLoss: 0.600521\n",
      "Train Epoch: 0 [209700/226408 (92%)]\tLoss: 0.518543\n",
      "Test epoch 0:\n",
      "accuaracy      sensitivity    specificity    BA             \n",
      "0.720233       0.787645       0.669095       0.728370       \n",
      "Train Epoch: 1 [29700/226408 (13%)]\tLoss: 0.479981\n",
      "Train Epoch: 1 [59700/226408 (26%)]\tLoss: 0.593505\n",
      "Train Epoch: 1 [89700/226408 (39%)]\tLoss: 0.437052\n",
      "Train Epoch: 1 [119700/226408 (52%)]\tLoss: 0.422278\n",
      "Train Epoch: 1 [149700/226408 (66%)]\tLoss: 0.425460\n",
      "Train Epoch: 1 [179700/226408 (79%)]\tLoss: 0.450910\n",
      "Train Epoch: 1 [209700/226408 (92%)]\tLoss: 0.444520\n",
      "Test epoch 1:\n",
      "accuaracy      sensitivity    specificity    BA             \n",
      "0.799931       0.787579       0.795613       0.791596       \n",
      "Train Epoch: 2 [29700/226408 (13%)]\tLoss: 0.379621\n",
      "Train Epoch: 2 [59700/226408 (26%)]\tLoss: 0.364777\n",
      "Train Epoch: 2 [89700/226408 (39%)]\tLoss: 0.336207\n",
      "Train Epoch: 2 [119700/226408 (52%)]\tLoss: 0.362401\n",
      "Train Epoch: 2 [149700/226408 (66%)]\tLoss: 0.325169\n",
      "Train Epoch: 2 [179700/226408 (79%)]\tLoss: 0.340214\n",
      "Train Epoch: 2 [209700/226408 (92%)]\tLoss: 0.392156\n",
      "Test epoch 2:\n",
      "accuaracy      sensitivity    specificity    BA             \n",
      "0.802472       0.824523       0.794871       0.809697       \n",
      "Train Epoch: 3 [29700/226408 (13%)]\tLoss: 0.464812\n",
      "Train Epoch: 3 [59700/226408 (26%)]\tLoss: 0.336003\n",
      "Train Epoch: 3 [89700/226408 (39%)]\tLoss: 0.353482\n",
      "Train Epoch: 3 [119700/226408 (52%)]\tLoss: 0.454562\n",
      "Train Epoch: 3 [149700/226408 (66%)]\tLoss: 0.313787\n",
      "Train Epoch: 3 [179700/226408 (79%)]\tLoss: 0.344830\n",
      "Train Epoch: 3 [209700/226408 (92%)]\tLoss: 0.359271\n",
      "Test epoch 3:\n",
      "accuaracy      sensitivity    specificity    BA             \n",
      "0.800975       0.833797       0.797875       0.815836       \n",
      "Train Epoch: 4 [29700/226408 (13%)]\tLoss: 0.372279\n",
      "Train Epoch: 4 [59700/226408 (26%)]\tLoss: 0.362892\n",
      "Train Epoch: 4 [89700/226408 (39%)]\tLoss: 0.359201\n",
      "Train Epoch: 4 [119700/226408 (52%)]\tLoss: 0.388289\n",
      "Train Epoch: 4 [149700/226408 (66%)]\tLoss: 0.314920\n",
      "Train Epoch: 4 [179700/226408 (79%)]\tLoss: 0.310476\n",
      "Train Epoch: 4 [209700/226408 (92%)]\tLoss: 0.316064\n",
      "Test epoch 4:\n",
      "accuaracy      sensitivity    specificity    BA             \n",
      "0.807579       0.835091       0.802889       0.818990       \n",
      "Train Epoch: 5 [29700/226408 (13%)]\tLoss: 0.362499\n",
      "Train Epoch: 5 [59700/226408 (26%)]\tLoss: 0.389780\n",
      "Train Epoch: 5 [89700/226408 (39%)]\tLoss: 0.365037\n",
      "Train Epoch: 5 [119700/226408 (52%)]\tLoss: 0.354191\n",
      "Train Epoch: 5 [149700/226408 (66%)]\tLoss: 0.293443\n",
      "Train Epoch: 5 [179700/226408 (79%)]\tLoss: 0.321417\n",
      "Train Epoch: 5 [209700/226408 (92%)]\tLoss: 0.332284\n",
      "Test epoch 5:\n",
      "accuaracy      sensitivity    specificity    BA             \n",
      "0.817197       0.837320       0.812835       0.825078       \n",
      "Train Epoch: 6 [29700/226408 (13%)]\tLoss: 0.466544\n",
      "Train Epoch: 6 [59700/226408 (26%)]\tLoss: 0.371779\n",
      "Train Epoch: 6 [89700/226408 (39%)]\tLoss: 0.338644\n",
      "Train Epoch: 6 [119700/226408 (52%)]\tLoss: 0.317095\n",
      "Train Epoch: 6 [149700/226408 (66%)]\tLoss: 0.332427\n",
      "Train Epoch: 6 [179700/226408 (79%)]\tLoss: 0.291691\n",
      "Train Epoch: 6 [209700/226408 (92%)]\tLoss: 0.397746\n",
      "Test epoch 6:\n",
      "accuaracy      sensitivity    specificity    BA             \n",
      "0.822744       0.837834       0.818693       0.828263       \n",
      "Train Epoch: 7 [29700/226408 (13%)]\tLoss: 0.358257\n",
      "Train Epoch: 7 [59700/226408 (26%)]\tLoss: 0.292800\n",
      "Train Epoch: 7 [89700/226408 (39%)]\tLoss: 0.308971\n",
      "Train Epoch: 7 [119700/226408 (52%)]\tLoss: 0.375816\n",
      "Train Epoch: 7 [149700/226408 (66%)]\tLoss: 0.319495\n",
      "Train Epoch: 7 [179700/226408 (79%)]\tLoss: 0.353583\n",
      "Train Epoch: 7 [209700/226408 (92%)]\tLoss: 0.358071\n",
      "Test epoch 7:\n",
      "accuaracy      sensitivity    specificity    BA             \n",
      "0.824485       0.843082       0.814429       0.828755       \n",
      "Train Epoch: 8 [29700/226408 (13%)]\tLoss: 0.356605\n",
      "Train Epoch: 8 [59700/226408 (26%)]\tLoss: 0.307608\n",
      "Train Epoch: 8 [89700/226408 (39%)]\tLoss: 0.333388\n",
      "Train Epoch: 8 [119700/226408 (52%)]\tLoss: 0.302630\n",
      "Train Epoch: 8 [149700/226408 (66%)]\tLoss: 0.313429\n",
      "Train Epoch: 8 [179700/226408 (79%)]\tLoss: 0.333171\n",
      "Train Epoch: 8 [209700/226408 (92%)]\tLoss: 0.385706\n",
      "Test epoch 8:\n",
      "accuaracy      sensitivity    specificity    BA             \n",
      "0.826110       0.839808       0.821834       0.830821       \n",
      "Train Epoch: 9 [29700/226408 (13%)]\tLoss: 0.422667\n",
      "Train Epoch: 9 [59700/226408 (26%)]\tLoss: 0.322610\n",
      "Train Epoch: 9 [89700/226408 (39%)]\tLoss: 0.345689\n",
      "Train Epoch: 9 [119700/226408 (52%)]\tLoss: 0.377913\n",
      "Train Epoch: 9 [149700/226408 (66%)]\tLoss: 0.299712\n",
      "Train Epoch: 9 [179700/226408 (79%)]\tLoss: 0.313412\n",
      "Train Epoch: 9 [209700/226408 (92%)]\tLoss: 0.333576\n",
      "Test epoch 9:\n",
      "accuaracy      sensitivity    specificity    BA             \n",
      "0.826992       0.844021       0.820008       0.832015       \n",
      "Train Epoch: 10 [29700/226408 (13%)]\tLoss: 0.358310\n",
      "Train Epoch: 10 [59700/226408 (26%)]\tLoss: 0.290324\n",
      "Train Epoch: 10 [89700/226408 (39%)]\tLoss: 0.361425\n",
      "Train Epoch: 10 [119700/226408 (52%)]\tLoss: 0.331070\n",
      "Train Epoch: 10 [149700/226408 (66%)]\tLoss: 0.293431\n",
      "Train Epoch: 10 [179700/226408 (79%)]\tLoss: 0.319882\n",
      "Train Epoch: 10 [209700/226408 (92%)]\tLoss: 0.273849\n",
      "Test epoch 10:\n",
      "accuaracy      sensitivity    specificity    BA             \n",
      "0.836905       0.832777       0.830235       0.831506       \n",
      "Train Epoch: 11 [29700/226408 (13%)]\tLoss: 0.354659\n",
      "Train Epoch: 11 [59700/226408 (26%)]\tLoss: 0.380883\n",
      "Train Epoch: 11 [89700/226408 (39%)]\tLoss: 0.382863\n",
      "Train Epoch: 11 [119700/226408 (52%)]\tLoss: 0.357657\n",
      "Train Epoch: 11 [149700/226408 (66%)]\tLoss: 0.356464\n",
      "Train Epoch: 11 [179700/226408 (79%)]\tLoss: 0.351050\n",
      "Train Epoch: 11 [209700/226408 (92%)]\tLoss: 0.374807\n",
      "Test epoch 11:\n",
      "accuaracy      sensitivity    specificity    BA             \n",
      "0.829824       0.844374       0.823941       0.834157       \n",
      "Train Epoch: 12 [29700/226408 (13%)]\tLoss: 0.388782\n",
      "Train Epoch: 12 [59700/226408 (26%)]\tLoss: 0.306419\n",
      "Train Epoch: 12 [89700/226408 (39%)]\tLoss: 0.399242\n",
      "Train Epoch: 12 [119700/226408 (52%)]\tLoss: 0.308923\n",
      "Train Epoch: 12 [149700/226408 (66%)]\tLoss: 0.393697\n",
      "Train Epoch: 12 [179700/226408 (79%)]\tLoss: 0.404102\n",
      "Train Epoch: 12 [209700/226408 (92%)]\tLoss: 0.395195\n",
      "Test epoch 12:\n",
      "accuaracy      sensitivity    specificity    BA             \n",
      "0.836107       0.841426       0.830178       0.835802       \n",
      "Train Epoch: 13 [29700/226408 (13%)]\tLoss: 0.304049\n",
      "Train Epoch: 13 [59700/226408 (26%)]\tLoss: 0.360524\n",
      "Train Epoch: 13 [89700/226408 (39%)]\tLoss: 0.297517\n",
      "Train Epoch: 13 [119700/226408 (52%)]\tLoss: 0.408171\n",
      "Train Epoch: 13 [149700/226408 (66%)]\tLoss: 0.406934\n",
      "Train Epoch: 13 [179700/226408 (79%)]\tLoss: 0.268922\n",
      "Train Epoch: 13 [209700/226408 (92%)]\tLoss: 0.359953\n",
      "Test epoch 13:\n",
      "accuaracy      sensitivity    specificity    BA             \n",
      "0.824681       0.850981       0.814668       0.832824       \n",
      "Train Epoch: 14 [29700/226408 (13%)]\tLoss: 0.314366\n",
      "Train Epoch: 14 [59700/226408 (26%)]\tLoss: 0.372800\n",
      "Train Epoch: 14 [89700/226408 (39%)]\tLoss: 0.390595\n",
      "Train Epoch: 14 [119700/226408 (52%)]\tLoss: 0.319189\n",
      "Train Epoch: 14 [149700/226408 (66%)]\tLoss: 0.334492\n",
      "Train Epoch: 14 [179700/226408 (79%)]\tLoss: 0.336898\n",
      "Train Epoch: 14 [209700/226408 (92%)]\tLoss: 0.260632\n",
      "Test epoch 14:\n",
      "accuaracy      sensitivity    specificity    BA             \n",
      "0.825935       0.849282       0.822726       0.836004       \n"
     ]
    }
   ],
   "source": [
    "# Initialize a model and train\n",
    "mlp = MLP_model([16, 16], target_label, epoches = 15, learning_rate = 0.00005)\n",
    "mlp.fit(X_train, y_train, X_val, y_val, M_train, M_val, report = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate = 0.00005 and train 15 epoches seem enough for get a good result\n"
     ]
    }
   ],
   "source": [
    "print('learning rate = 0.00005 and train 15 epoches seem enough for get a good result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 33.2min\n",
      "[Parallel(n_jobs=-1)]: Done 225 out of 225 | elapsed: 48.3min finished\n",
      "\n",
      "[2020-04-19 00:06:15] Features: 224/175 -- score: 0.8465497427982834[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=-1)]: Done 224 out of 224 | elapsed: 50.0min finished\n",
      "\n",
      "[2020-04-19 00:56:14] Features: 223/175 -- score: 0.8441079197433[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=-1)]: Done 223 out of 223 | elapsed: 48.2min finished\n",
      "\n",
      "[2020-04-19 01:44:23] Features: 222/175 -- score: 0.8455511639168928[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 32.5min\n",
      "[Parallel(n_jobs=-1)]: Done 222 out of 222 | elapsed: 541.6min finished\n",
      "\n",
      "[2020-04-19 10:45:59] Features: 221/175 -- score: 0.8458030125939991[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=-1)]: Done 221 out of 221 | elapsed: 32.5min finished\n",
      "\n",
      "[2020-04-19 11:18:29] Features: 220/175 -- score: 0.8466014293340459[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  5.3min\n"
     ]
    }
   ],
   "source": [
    "# 50 min select one feature with epoch 40\n",
    "# if we reduce to 15 epoch, it will take 19 min to select a feature\n",
    "# Total time if we do SBS: 19/225 * (175 + 225)/2 * 50 min = 14 h\n",
    "# Seems a possible time to reach now! \n",
    "\n",
    "mlp = MLP_model([16, 16], target_label, epoches = 15, learning_rate = 0.00005)\n",
    "\n",
    "BA_val_scoring = make_scorer(score_function, W_test = abs(1-M_train))\n",
    "sbs = SFS(mlp, \n",
    "           k_features=175, \n",
    "           forward=False, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring=BA_val_scoring,\n",
    "           n_jobs = -1,  \n",
    "           cv=0)\n",
    "sbs.fit(X_train, y_train, M_train = M_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
